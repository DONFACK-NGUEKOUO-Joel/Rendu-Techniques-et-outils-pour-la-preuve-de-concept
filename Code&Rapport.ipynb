{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d176be0",
   "metadata": {},
   "source": [
    "### <u>Techniques et Outils pour la Preuve de Concept</u>: GrAMeFFSI (Graph Analysis Based Message Format and Field Semantics Inference For Binary Protocols, Using Recorded Network Traffic)\n",
    "\n",
    "#### Referance du papier: \n",
    "G. Ládi, L. Buttyán et T. Holczer,  \n",
    "**“Message Format and Field Semantics Inference for Binary Protocols Using Recorded Network Traffic,”**  \n",
    "*2018 26th International Conference on Software, Telecommunications and Computer Networks (SoftCOM)*,  \n",
    "Split, Croatia, 2018, pp. 1–6.  \n",
    "DOI: [https://doi.org/10.23919/SOFTCOM.2018.8555813](https://doi.org/10.23919/SOFTCOM.2018.8555813)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a489ff5",
   "metadata": {},
   "source": [
    "### <center><u><h2>Introduction au problème et à la modélisation</h2></u></center>\n",
    "Les protocoles binaires propriétaires sont aujourd'hui largement utilisés dans des domaines tels que l'industrie, l'IoT ou les systèmes embarqués, mais leurs spécifications ne sont pas toujours rendues publiques, ce qui complique l’analyse de sécurité. Pour analyser ou sécuriser ces systèmes, il faut comprendre la structure interne des messages (champs, longueur, type, signification), mais sans avoir la spécification du protocole. Afin de résoudre ce problème, l'algorithme GrAMeFFSI, proposé dans cet article, vise à inférer automatiquement les types de messages et la sémantique de certains champs d’un protocole binaire à partir de simples captures réseau, sans accès au code ni aux binaires.\n",
    "\n",
    "Dans ce projet, l’objectif est de reproduire l’approche GrAMeFFSI sur un jeu de données existant, de comparer les modèles inférés à une spécification de référence du protocole étudié, puis d’analyser les performances et la reproductibilité de la publication originale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac325e9e",
   "metadata": {},
   "source": [
    "### 1- Critères d’évaluation de la solution \n",
    "La qualité d’une solution de reverse engineering de protocoles est mesurée par trois métriques classiques : exactitude, concision et couverture. GrAMeFFSI ajoute deux métriques spécifiques pour la sémantique des champs : précision et précision ajustée.\n",
    "* <u>exactitude</u> : proportion de types de messages inférés qui correspondent réellement à un type de message valide ;\n",
    "* <u>concision</u> : degré de duplication des modèles, approximativement ;\n",
    "* <u>couverture</u> : part des types de messages réels qui sont présents dans les modèles inférés ;\n",
    "* <u>précision</u> : proportion de champs dont la sémantique (constante, compteur, longueur, chaîne, etc.) est correctement inférée, calculée à l’aide d’une distance d’édition d’arbres entre modèle vrai et modèle inféré ;\n",
    "* <u>précision ajustée</u> : même calcul, mais en tolérant certaines erreurs dues à un trafic peu varié (par exemple un compteur vu comme constante si la valeur haute n’apparaît jamais);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b814a4d0",
   "metadata": {},
   "source": [
    "### 2- Jeu de données de référence\n",
    "L’article évalue l’algorithme GrAMeFFSI sur des traces Modbus et MQTT obtenues dans un environnement contrôlé, avec une génération de trafic riche et varié. Pour Modbus, les auteurs capturent des requêtes ou réponses entre un client et un serveur, puis comparent les modèles inférés à la spécification officielle Modbus. Pour MQTT, ils utilisent un broker Eclipse Mosquitto et un client Web HiveMQ, et couvrent les 14 types de messages définis par le standard, pour environ 1200 paquets.\n",
    "\n",
    "Pour notre cas de preuve de concept, le jeu de données utilisé provient d’un dépôt GitHub existant qui utilise des captures réseau similaires au protocole TCP dont nous avons besoin pour notre programme. Le dataset consiste en un fichier .pcap contenant N paquets capturés lors d’échanges entre un client et un serveur.\n",
    "* Protocole ciblé :\n",
    "Dans notre cas d'etude, le protocole étudié est le Modbus/TCP. Sa spécification de référence est disponible dans [(https://github.com/ITI/ICS-Security-Tools/blob/master/pcaps/ModbusTCP/README.md)] et elle nous servira de base au modèle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1996781f",
   "metadata": {},
   "source": [
    "### 3- Résolution du problème de modélisation\n",
    "L’algorithme GrAMeFFSI se subdivise en cinq phases : \n",
    "* préparation du jeu de donne;\n",
    "* construction des arbres;\n",
    "* fusion des modèles;\n",
    "* optimisations;\n",
    "*puis énumération des types de messages et des sémantiques de champs. \n",
    "Chaque arbre est un graphe orienté acyclique enraciné où chaque nœud représente un champ identifié (constante, compteur, longueur, chaîne, type énuméré, champ très variable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bac81e",
   "metadata": {},
   "source": [
    "#### Étape 1: Script pour lire le fichier .PCAP et extraire les payloads TCP Modbus\n",
    "Cette étape initiale consiste à nettoyer et à normaliser les données capturées (fichiers PCAP). L'objectif est de s'assurer que l'algorithme travaille sur des flux de données cohérents en filtrant le bruit réseau et en uniformisant les adresses et ports sources/destinations, afin que tous les messages d'un même protocole soient traités comme un ensemble homogène."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cabb9465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de messages Modbus trouvés : 13390\n",
      "                                     flow  length  \\\n",
      "0  (141.81.0.86, 502, 141.81.0.10, 57184)       6   \n",
      "1  (141.81.0.10, 57184, 141.81.0.86, 502)      12   \n",
      "2  (141.81.0.86, 502, 141.81.0.10, 57184)     273   \n",
      "3  (141.81.0.10, 57184, 141.81.0.86, 502)      12   \n",
      "4  (141.81.0.86, 502, 141.81.0.10, 57184)      26   \n",
      "\n",
      "                                             payload  \n",
      "0                           b'|\\xf6\\x00\\x00\\x00\\x07'  \n",
      "1  b'\\x00\\x00\\x00\\x00\\x00\\x06\\xff\\x04\\x08\\xd2\\x00...  \n",
      "2  b'|\\xfe\\x00\\x00\\x00\\xc9\\xff\\x04\\xc6\\x00\\x00\\x0...  \n",
      "3   b'\\x00\\x01\\x00\\x00\\x00\\x06\\xff\\x02\\x00c\\x00\\x1e'  \n",
      "4  b'\\x00\\x00\\x00\\x00\\x00\\x07\\xff\\x04\\x04\\x00\\x00...  \n"
     ]
    }
   ],
   "source": [
    "from scapy.all import rdpcap, TCP\n",
    "import pandas as pd\n",
    "\n",
    "PCAP_FILE = \"Modbus_capture.pcap\"  # adapte si l'extension est différente\n",
    "MODBUS_PORT = 502  # port Modbus/TCP standard\n",
    "\n",
    "def extract_modbus_messages(pcap_file):\n",
    "    packets = rdpcap(pcap_file)\n",
    "    messages = []\n",
    "\n",
    "    for pkt in packets:\n",
    "        # On garde uniquement les paquets TCP avec du Modbus (port 502 client ou serveur)\n",
    "        if TCP in pkt and (pkt[TCP].sport == MODBUS_PORT or pkt[TCP].dport == MODBUS_PORT):\n",
    "            payload_bytes = bytes(pkt[TCP].payload)\n",
    "            if len(payload_bytes) == 0:\n",
    "                continue  # pas de données applicatives\n",
    "\n",
    "            # Clé de flux : (IP_src, port_src, IP_dst, port_dst)\n",
    "            try:\n",
    "                ip_layer = pkt[\"IP\"]\n",
    "                flow_key = (\n",
    "                    ip_layer.src,\n",
    "                    pkt[TCP].sport,\n",
    "                    ip_layer.dst,\n",
    "                    pkt[TCP].dport,\n",
    "                )\n",
    "            except Exception:\n",
    "                # Ignore paquets bizarres sans IP (par ex. IPv6 si pas géré ici)\n",
    "                continue\n",
    "\n",
    "            messages.append({\n",
    "                \"flow\": flow_key,\n",
    "                \"length\": len(payload_bytes),\n",
    "                \"payload\": payload_bytes,\n",
    "            })\n",
    "\n",
    "    # DataFrame pratique pour la suite\n",
    "    df = pd.DataFrame(messages)\n",
    "    return df\n",
    "\n",
    "df = extract_modbus_messages(PCAP_FILE)\n",
    "print(\"Nombre de messages Modbus trouvés :\", len(df))\n",
    "print(df.head())\n",
    "# Sauvegarde brute pour debug / étape suivante\n",
    "df.to_pickle(\"modbus_messages.pkl\")  # pour recharger facilement plus tard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed117dc",
   "metadata": {},
   "source": [
    "#### Etape 2: Construction d’un arbre par flux\n",
    "Ici, l'algorithme parcourt chaque octet des messages pour construire un arbre de flux (Flow Tree). Chaque nœud de l'arbre représente un champ du protocole, et les branches illustrent les différentes valeurs possibles. Cette structure permet de visualiser la hiérarchie et les dépendances entre les champs de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a60124ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de flux trouvés : 28\n",
      "Premier flux : ('141.81.0.10', 50594, '141.81.0.84', 502)\n",
      "Nombre de messages dans ce flux : 530\n",
      "Premier message (longueur) : 12\n",
      "Premiers octets : [25, 137, 0, 0, 0, 6, 255, 4, 0, 48, 0, 40]\n",
      "Sauvegardé dans modbus_flows.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "INPUT_PICKLE = \"modbus_messages.pkl\"\n",
    "OUTPUT_PICKLE = \"modbus_flows.pkl\"\n",
    "\n",
    "def load_messages():\n",
    "    df = pd.read_pickle(INPUT_PICKLE)\n",
    "    # On trie un peu pour avoir un ordre stable (optionnel)\n",
    "    df = df.sort_values(by=[\"flow\", \"length\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def group_by_flow(df):\n",
    "    flows = {}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        flow_key = row[\"flow\"]          # tuple (src_ip, sport, dst_ip, dport)\n",
    "        payload = row[\"payload\"]        # type bytes\n",
    "        if flow_key not in flows:\n",
    "            flows[flow_key] = []\n",
    "        # Chaque message est une liste d'octets, ce que l’algorithme considère comme une \"séquence\"\n",
    "        flows[flow_key].append(list(payload))\n",
    "\n",
    "    return flows\n",
    "\n",
    "\n",
    "df = load_messages()\n",
    "flows = group_by_flow(df)\n",
    "\n",
    "print(\"Nombre de flux trouvés :\", len(flows))\n",
    "# Affichage d'exemple : 1er flux, 1er message (tronqué)\n",
    "first_flow = next(iter(flows))\n",
    "print(\"Premier flux :\", first_flow)\n",
    "print(\"Nombre de messages dans ce flux :\", len(flows[first_flow]))\n",
    "print(\"Premier message (longueur) :\", len(flows[first_flow][0]))\n",
    "print(\"Premiers octets :\", flows[first_flow][0][:16])\n",
    "\n",
    "# Sauvegarde pour les étapes suivantes (construction des arbres)\n",
    "pd.to_pickle(flows, OUTPUT_PICKLE)\n",
    "print(\"Sauvegardé dans\", OUTPUT_PICKLE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b5e54a",
   "metadata": {},
   "source": [
    "#### Etape 3: \tFusion des modèles\n",
    "Afin de simplifier l'arbre et d'identifier les structures répétitives, dans cette étape nous fusionnons les nœuds qui présentent des caractéristiques similaires. Cette étape est cruciale pour passer d'une simple représentation des messages capturés à un modèle généralisé capable de décrire le format global du protocole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a399018d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construction de l'arbre pour le flux ('141.81.0.10', 50594, '141.81.0.84', 502) (messages: 530)\n",
      "Construction de l'arbre pour le flux ('141.81.0.10', 51411, '141.81.0.26', 502) (messages: 363)\n",
      "Construction de l'arbre pour le flux ('141.81.0.10', 53414, '141.81.0.44', 502) (messages: 480)\n",
      "Construction de l'arbre pour le flux ('141.81.0.10', 54138, '141.81.0.66', 502) (messages: 535)\n",
      "Construction de l'arbre pour le flux ('141.81.0.10', 57184, '141.81.0.86', 502) (messages: 555)\n",
      "Construction de l'arbre pour le flux ('141.81.0.10', 59598, '141.81.0.163', 502) (messages: 426)\n",
      "Construction de l'arbre pour le flux ('141.81.0.10', 59599, '141.81.0.143', 502) (messages: 382)\n",
      "Construction de l'arbre pour le flux ('141.81.0.10', 59758, '141.81.0.46', 502) (messages: 197)\n",
      "Construction de l'arbre pour le flux ('141.81.0.10', 59796, '141.81.0.46', 502) (messages: 88)\n",
      "Construction de l'arbre pour le flux ('141.81.0.10', 64338, '141.81.0.24', 502) (messages: 544)\n",
      "Construction de l'arbre pour le flux ('141.81.0.10', 64340, '141.81.0.104', 502) (messages: 495)\n",
      "Construction de l'arbre pour le flux ('141.81.0.10', 64341, '141.81.0.144', 502) (messages: 371)\n",
      "Construction de l'arbre pour le flux ('141.81.0.10', 64342, '141.81.0.164', 502) (messages: 372)\n",
      "Construction de l'arbre pour le flux ('141.81.0.10', 64368, '141.81.0.64', 502) (messages: 510)\n",
      "Construction de l'arbre pour le flux ('141.81.0.104', 502, '141.81.0.10', 64340) (messages: 540)\n",
      "Construction de l'arbre pour le flux ('141.81.0.143', 502, '141.81.0.10', 59599) (messages: 615)\n",
      "Construction de l'arbre pour le flux ('141.81.0.144', 502, '141.81.0.10', 64341) (messages: 413)\n",
      "Construction de l'arbre pour le flux ('141.81.0.163', 502, '141.81.0.10', 59598) (messages: 695)\n",
      "Construction de l'arbre pour le flux ('141.81.0.164', 502, '141.81.0.10', 64342) (messages: 415)\n",
      "Construction de l'arbre pour le flux ('141.81.0.24', 502, '141.81.0.10', 64338) (messages: 588)\n",
      "Construction de l'arbre pour le flux ('141.81.0.26', 502, '141.81.0.10', 51411) (messages: 530)\n",
      "Construction de l'arbre pour le flux ('141.81.0.44', 502, '141.81.0.10', 53414) (messages: 527)\n",
      "Construction de l'arbre pour le flux ('141.81.0.46', 502, '141.81.0.10', 59758) (messages: 294)\n",
      "Construction de l'arbre pour le flux ('141.81.0.46', 502, '141.81.0.10', 59796) (messages: 147)\n",
      "Construction de l'arbre pour le flux ('141.81.0.64', 502, '141.81.0.10', 64368) (messages: 553)\n",
      "Construction de l'arbre pour le flux ('141.81.0.66', 502, '141.81.0.10', 54138) (messages: 832)\n",
      "Construction de l'arbre pour le flux ('141.81.0.84', 502, '141.81.0.10', 50594) (messages: 576)\n",
      "Construction de l'arbre pour le flux ('141.81.0.86', 502, '141.81.0.10', 57184) (messages: 817)\n",
      "Premier flux : ('141.81.0.10', 50594, '141.81.0.84', 502)\n",
      "Nombre de noeuds dans son arbre : 7098\n",
      "Nombre d'arêtes dans son arbre : 7097\n",
      "Successeurs directs de la racine : [(1, 25, 101), (761, 26, 220), (2423, 27, 209)]\n",
      "Sauvegardé dans modbus_trees.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "INPUT_FLOWS = \"modbus_flows.pkl\"\n",
    "OUTPUT_TREES = \"modbus_trees.pkl\"\n",
    "\n",
    "def load_flows():\n",
    "    flows = pd.read_pickle(INPUT_FLOWS)\n",
    "    return flows  \n",
    "\n",
    "def build_prefix_tree_for_flow(messages):\n",
    "    G = nx.DiGraph()\n",
    "    root = 0\n",
    "    G.add_node(root, byte=None, count=0)  \n",
    "\n",
    "    next_node_id = 1\n",
    "\n",
    "    for msg in messages:\n",
    "        current = root\n",
    "        G.nodes[current][\"count\"] += 1  # ce nombre de messages passe par ce nœud\n",
    "\n",
    "        for b in msg:\n",
    "            child = None\n",
    "            for succ in G.successors(current):\n",
    "                if G.nodes[succ].get(\"byte\") == b:\n",
    "                    child = succ\n",
    "                    break\n",
    "\n",
    "            if child is None:\n",
    "                child = next_node_id\n",
    "                next_node_id += 1\n",
    "                G.add_node(child, byte=b, count=0)\n",
    "                G.add_edge(current, child)\n",
    "\n",
    "            current = child\n",
    "            G.nodes[current][\"count\"] += 1\n",
    "\n",
    "    return G, root\n",
    "\n",
    "def build_trees_for_all_flows(flows):\n",
    "    trees = {}\n",
    "    for flow_key, messages in flows.items():\n",
    "        print(f\"Construction de l'arbre pour le flux {flow_key} (messages: {len(messages)})\")\n",
    "        G, root = build_prefix_tree_for_flow(messages)\n",
    "        trees[flow_key] = (G, root)\n",
    "    return trees\n",
    "\n",
    "\n",
    "flows = load_flows()\n",
    "trees = build_trees_for_all_flows(flows)\n",
    "\n",
    "# Exemple d'inspection : 1er flux\n",
    "first_flow = next(iter(trees))\n",
    "G, root = trees[first_flow]\n",
    "print(\"Premier flux :\", first_flow)\n",
    "print(\"Nombre de noeuds dans son arbre :\", G.number_of_nodes())\n",
    "print(\"Nombre d'arêtes dans son arbre :\", G.number_of_edges())\n",
    "print(\"Successeurs directs de la racine :\",\n",
    "    [(n, G.nodes[n].get(\"byte\"), G.nodes[n].get(\"count\")) for n in G.successors(root)][:10])\n",
    "\n",
    "# Sauvegarde pour les phases suivantes (fusion / optimisation)\n",
    "pd.to_pickle(trees, OUTPUT_TREES)\n",
    "print(\"Sauvegardé dans\", OUTPUT_TREES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf52f3b",
   "metadata": {},
   "source": [
    "#### Etape 4: \tPhase d'Optimisation\n",
    "Cette étape permet d'affiner le modèle en appliquant des heuristiques spécifiques pour corriger les erreurs d'interprétation courantes. Elle traite notamment deux cas complexes : la détection des champs de longueur variable (qui peuvent décaler la structure) et la suppression des faux types énumérés qui pourraient apparaître."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec83f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marquage des noeuds pour le flux ('141.81.0.10', 50594, '141.81.0.84', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.10', 51411, '141.81.0.26', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.10', 53414, '141.81.0.44', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.10', 54138, '141.81.0.66', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.10', 57184, '141.81.0.86', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.10', 59598, '141.81.0.163', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.10', 59599, '141.81.0.143', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.10', 59758, '141.81.0.46', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.10', 59796, '141.81.0.46', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.10', 64338, '141.81.0.24', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.10', 64340, '141.81.0.104', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.10', 64341, '141.81.0.144', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.10', 64342, '141.81.0.164', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.10', 64368, '141.81.0.64', 502)\n",
      "Marquage des noeuds pour le flux ('141.81.0.104', 502, '141.81.0.10', 64340)\n",
      "Marquage des noeuds pour le flux ('141.81.0.143', 502, '141.81.0.10', 59599)\n",
      "Marquage des noeuds pour le flux ('141.81.0.144', 502, '141.81.0.10', 64341)\n",
      "Marquage des noeuds pour le flux ('141.81.0.163', 502, '141.81.0.10', 59598)\n",
      "Marquage des noeuds pour le flux ('141.81.0.164', 502, '141.81.0.10', 64342)\n",
      "Marquage des noeuds pour le flux ('141.81.0.24', 502, '141.81.0.10', 64338)\n",
      "Marquage des noeuds pour le flux ('141.81.0.26', 502, '141.81.0.10', 51411)\n",
      "Marquage des noeuds pour le flux ('141.81.0.44', 502, '141.81.0.10', 53414)\n",
      "Marquage des noeuds pour le flux ('141.81.0.46', 502, '141.81.0.10', 59758)\n",
      "Marquage des noeuds pour le flux ('141.81.0.46', 502, '141.81.0.10', 59796)\n",
      "Marquage des noeuds pour le flux ('141.81.0.64', 502, '141.81.0.10', 64368)\n",
      "Marquage des noeuds pour le flux ('141.81.0.66', 502, '141.81.0.10', 54138)\n",
      "Marquage des noeuds pour le flux ('141.81.0.84', 502, '141.81.0.10', 50594)\n",
      "Marquage des noeuds pour le flux ('141.81.0.86', 502, '141.81.0.10', 57184)\n",
      "Premier flux : ('141.81.0.10', 50594, '141.81.0.84', 502)\n",
      "Exemples de successeurs de la racine avec types :\n",
      "(1, 25, 101, 0.191, 'variable')\n",
      "(761, 26, 220, 0.415, 'variable')\n",
      "(2423, 27, 209, 0.394, 'variable')\n",
      "Sauvegardé dans modbus_trees_tagged.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "INPUT_TREES = \"modbus_trees.pkl\"\n",
    "OUTPUT_TREES = \"modbus_trees_tagged.pkl\"\n",
    "\n",
    "THRESHOLD = 0.95  # seuil pour considérer un octet comme constant\n",
    "\n",
    "def load_trees():\n",
    "    trees = pd.read_pickle(INPUT_TREES)\n",
    "    return trees  \n",
    "\n",
    "def mark_node_types(G, root, threshold=THRESHOLD):\n",
    "   \n",
    "    G.nodes[root][\"type\"] = \"root\"\n",
    "    G.nodes[root][\"ratio\"] = 1.0\n",
    "\n",
    "    for parent, child in G.edges():\n",
    "        parent_count = G.nodes[parent].get(\"count\", 0)\n",
    "        child_count = G.nodes[child].get(\"count\", 0)\n",
    "\n",
    "        if parent_count == 0:\n",
    "            ratio = 0.0\n",
    "        else:\n",
    "            ratio = child_count / parent_count\n",
    "\n",
    "        G.nodes[child][\"ratio\"] = ratio\n",
    "        if ratio >= threshold:\n",
    "            G.nodes[child][\"type\"] = \"constant\"\n",
    "        else:\n",
    "            G.nodes[child][\"type\"] = \"variable\"\n",
    "\n",
    "def process_all_trees(trees, threshold=THRESHOLD):\n",
    "    for flow_key, (G, root) in trees.items():\n",
    "        print(f\"Marquage des noeuds pour le flux {flow_key}\")\n",
    "        mark_node_types(G, root, threshold)\n",
    "    return trees\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trees = load_trees()\n",
    "    trees_tagged = process_all_trees(trees, THRESHOLD)\n",
    "\n",
    "    # Exemple d'inspection sur le premier flux\n",
    "    first_flow = next(iter(trees_tagged))\n",
    "    G, root = trees_tagged[first_flow]\n",
    "    print(\"Premier flux :\", first_flow)\n",
    "    print(\"Exemples de successeurs de la racine avec types :\")\n",
    "    examples = []\n",
    "    for child in G.successors(root):\n",
    "        node_data = G.nodes[child]\n",
    "        examples.append(\n",
    "            (child, node_data.get(\"byte\"), node_data.get(\"count\"),\n",
    "             round(node_data.get(\"ratio\", 0.0), 3),\n",
    "             node_data.get(\"type\"))\n",
    "        )\n",
    "        if len(examples) >= 10:\n",
    "            break\n",
    "    for e in examples:\n",
    "        print(e)\n",
    "\n",
    "    # Sauvegarde\n",
    "    pd.to_pickle(trees_tagged, OUTPUT_TREES)\n",
    "    print(\"Sauvegardé dans\", OUTPUT_TREES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa893bd3",
   "metadata": {},
   "source": [
    "### Etape 5: Phase d'Interprétation Sémantique (Field Semantics Interpretation)\n",
    "La dernière étape consiste à donner un sens aux données identifiées. L'algorithme analyse les valeurs des champs pour leur attribuer un rôle sémantique : constante (ID de protocole), compteur (numéro de séquence), longueur de charge utile ou encore chaînes de caractères."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c2a574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flux analysé : ('141.81.0.10', 50594, '141.81.0.84', 502)\n",
      "Position | C/V | Octets constants (hex)\n",
      "       1 |  V  | -\n",
      "       2 |  V  | -\n",
      "       3 |  C  | 0x00\n",
      "       4 |  C  | 0x00\n",
      "       5 |  C  | 0x00\n",
      "       6 |  C  | 0x06, 0x08\n",
      "       7 |  C  | 0xFF\n",
      "       8 |  C  | 0x01, 0x02, 0x04, 0x0F\n",
      "       9 |  C  | 0x00, 0x04\n",
      "      10 |  C  | 0x00, 0x05, 0x30, 0x4C, 0xCB\n",
      "      11 |  C  | 0x00\n",
      "      12 |  C  | 0x01, 0x07, 0x0A, 0x1E, 0x28, 0x73\n",
      "      13 |  C  | 0x01, 0x19, 0x1A, 0x1B\n",
      "      14 |  C  | 0x00, 0x01, 0x07, 0x12, 0x13, 0x1D, 0x27, 0x28, 0x31, 0x3B, 0x45, 0x53, 0x5D, 0x60, 0x6A, 0x6E, 0x76, 0x7B, 0x87, 0x8B, 0x91, 0x93, 0x97, 0xA1, 0xA7, 0xAD, 0xB4, 0xB6, 0xBA, 0xC3, 0xC5, 0xCE, 0xD0, 0xD9, 0xDC, 0xE6, 0xE7, 0xE8, 0xF1, 0xF8, 0xFC\n",
      "      15 |  C  | 0x00\n",
      "      16 |  C  | 0x00\n",
      "      17 |  C  | 0x00\n",
      "      18 |  C  | 0x06\n",
      "      19 |  C  | 0xFF\n",
      "      20 |  C  | 0x04\n",
      "      21 |  C  | 0x05\n",
      "      22 |  C  | 0x14\n",
      "      23 |  C  | 0x00\n",
      "      24 |  C  | 0x04\n",
      "      25 |  C  | 0x19, 0x1A, 0x1B\n",
      "      26 |  C  | 0x08, 0x13, 0x14, 0x1E, 0x28, 0x29, 0x32, 0x3C, 0x46, 0x54, 0x5E, 0x61, 0x6B, 0x6F, 0x77, 0x7C, 0x88, 0x8C, 0x92, 0x94, 0x98, 0xA2, 0xA8, 0xAE, 0xB5, 0xB7, 0xBB, 0xC4, 0xC6, 0xCF, 0xD1, 0xDA, 0xDD, 0xE7, 0xE8, 0xE9, 0xF2, 0xF9, 0xFD\n",
      "      27 |  C  | 0x00\n",
      "      28 |  C  | 0x00\n",
      "      29 |  C  | 0x00\n",
      "      30 |  C  | 0x06, 0x08\n",
      "      31 |  C  | 0xFF\n",
      "      32 |  C  | 0x02, 0x0F\n",
      "      33 |  C  | 0x00\n",
      "      34 |  C  | 0x00, 0xCB\n",
      "      35 |  C  | 0x00\n",
      "      36 |  C  | 0x01, 0x1E\n",
      "      37 |  C  | 0x01\n",
      "      38 |  C  | 0x01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "INPUT_TREES_TAGGED = \"modbus_trees_tagged.pkl\"\n",
    "\n",
    "def load_tagged_trees():\n",
    "    trees = pd.read_pickle(INPUT_TREES_TAGGED)\n",
    "    return trees  \n",
    "\n",
    "def compute_depths(G, root):\n",
    "    depths = {root: 0}\n",
    "    queue = deque([root])\n",
    "\n",
    "    while queue:\n",
    "        current = queue.popleft()\n",
    "        current_depth = depths[current]\n",
    "        for child in G.successors(current):\n",
    "            if child not in depths:\n",
    "                depths[child] = current_depth + 1\n",
    "                queue.append(child)\n",
    "\n",
    "    return depths\n",
    "\n",
    "def summarize_constants_by_depth(G, root):\n",
    "    depths = compute_depths(G, root)\n",
    "\n",
    "    const_bytes_per_depth = defaultdict(set)\n",
    "    has_node_at_depth = defaultdict(bool)\n",
    "\n",
    "    for node, depth in depths.items():\n",
    "        node_type = G.nodes[node].get(\"type\")\n",
    "        byte_val = G.nodes[node].get(\"byte\")\n",
    "\n",
    "        if depth == 0:\n",
    "            continue  # racine\n",
    "\n",
    "        has_node_at_depth[depth] = True\n",
    "\n",
    "        if node_type == \"constant\" and byte_val is not None:\n",
    "            const_bytes_per_depth[depth].add(byte_val)\n",
    "\n",
    "    # Préparer un résumé ordonné par profondeur\n",
    "    summary = []\n",
    "    for depth in sorted(has_node_at_depth.keys()):\n",
    "        const_bytes = const_bytes_per_depth.get(depth, set())\n",
    "        if const_bytes:\n",
    "            label = \"C\"\n",
    "        else:\n",
    "            label = \"V\"\n",
    "        const_hex = [f\"0x{b:02X}\" for b in sorted(const_bytes)]\n",
    "        summary.append((depth, label, const_hex))\n",
    "\n",
    "    return summary\n",
    "\n",
    "def print_summary_for_flow(flow_key, G, root):\n",
    "    print(\"Flux analysé :\", flow_key)\n",
    "    summary = summarize_constants_by_depth(G, root)\n",
    "    print(\"Position | C/V | Octets constants (hex)\")\n",
    "    for depth, label, const_hex in summary:\n",
    "        print(f\"{depth:8d} |  {label}  | {', '.join(const_hex) if const_hex else '-'}\")\n",
    "\n",
    "\n",
    "trees_tagged = load_tagged_trees()\n",
    "\n",
    "# Choix d'un flux à analyser : ici le premier par défaut\n",
    "first_flow = next(iter(trees_tagged))\n",
    "G, root = trees_tagged[first_flow]\n",
    "\n",
    "print_summary_for_flow(first_flow, G, root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a41a0",
   "metadata": {},
   "source": [
    "## construction de l'arbre global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf4659cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construction de l'arbre global...\n",
      "Ajout des messages du flux ('141.81.0.10', 50594, '141.81.0.84', 502) (messages: 530)\n",
      "Ajout des messages du flux ('141.81.0.10', 51411, '141.81.0.26', 502) (messages: 363)\n",
      "Ajout des messages du flux ('141.81.0.10', 53414, '141.81.0.44', 502) (messages: 480)\n",
      "Ajout des messages du flux ('141.81.0.10', 54138, '141.81.0.66', 502) (messages: 535)\n",
      "Ajout des messages du flux ('141.81.0.10', 57184, '141.81.0.86', 502) (messages: 555)\n",
      "Ajout des messages du flux ('141.81.0.10', 59598, '141.81.0.163', 502) (messages: 426)\n",
      "Ajout des messages du flux ('141.81.0.10', 59599, '141.81.0.143', 502) (messages: 382)\n",
      "Ajout des messages du flux ('141.81.0.10', 59758, '141.81.0.46', 502) (messages: 197)\n",
      "Ajout des messages du flux ('141.81.0.10', 59796, '141.81.0.46', 502) (messages: 88)\n",
      "Ajout des messages du flux ('141.81.0.10', 64338, '141.81.0.24', 502) (messages: 544)\n",
      "Ajout des messages du flux ('141.81.0.10', 64340, '141.81.0.104', 502) (messages: 495)\n",
      "Ajout des messages du flux ('141.81.0.10', 64341, '141.81.0.144', 502) (messages: 371)\n",
      "Ajout des messages du flux ('141.81.0.10', 64342, '141.81.0.164', 502) (messages: 372)\n",
      "Ajout des messages du flux ('141.81.0.10', 64368, '141.81.0.64', 502) (messages: 510)\n",
      "Ajout des messages du flux ('141.81.0.104', 502, '141.81.0.10', 64340) (messages: 540)\n",
      "Ajout des messages du flux ('141.81.0.143', 502, '141.81.0.10', 59599) (messages: 615)\n",
      "Ajout des messages du flux ('141.81.0.144', 502, '141.81.0.10', 64341) (messages: 413)\n",
      "Ajout des messages du flux ('141.81.0.163', 502, '141.81.0.10', 59598) (messages: 695)\n",
      "Ajout des messages du flux ('141.81.0.164', 502, '141.81.0.10', 64342) (messages: 415)\n",
      "Ajout des messages du flux ('141.81.0.24', 502, '141.81.0.10', 64338) (messages: 588)\n",
      "Ajout des messages du flux ('141.81.0.26', 502, '141.81.0.10', 51411) (messages: 530)\n",
      "Ajout des messages du flux ('141.81.0.44', 502, '141.81.0.10', 53414) (messages: 527)\n",
      "Ajout des messages du flux ('141.81.0.46', 502, '141.81.0.10', 59758) (messages: 294)\n",
      "Ajout des messages du flux ('141.81.0.46', 502, '141.81.0.10', 59796) (messages: 147)\n",
      "Ajout des messages du flux ('141.81.0.64', 502, '141.81.0.10', 64368) (messages: 553)\n",
      "Ajout des messages du flux ('141.81.0.66', 502, '141.81.0.10', 54138) (messages: 832)\n",
      "Ajout des messages du flux ('141.81.0.84', 502, '141.81.0.10', 50594) (messages: 576)\n",
      "Ajout des messages du flux ('141.81.0.86', 502, '141.81.0.10', 57184) (messages: 817)\n",
      "Nombre de noeuds : 352007\n",
      "Nombre d'arêtes : 352006\n",
      "Marquage constant / variable...\n",
      "Niveau 1 (après la racine) :\n",
      "1 25 211 0.016 variable\n",
      "761 26 460 0.034 variable\n",
      "2423 27 434 0.032 variable\n",
      "7098 72 233 0.017 variable\n",
      "7583 73 355 0.027 variable\n",
      "8420 74 169 0.013 variable\n",
      "13634 2 726 0.054 variable\n",
      "14856 3 615 0.046 variable\n",
      "16419 4 198 0.015 variable\n",
      "20316 5 150 0.011 variable\n",
      "20691 6 323 0.024 variable\n",
      "21561 7 326 0.024 variable\n",
      "22486 8 359 0.027 variable\n",
      "24732 9 23 0.002 variable\n",
      "30786 0 332 0.025 variable\n",
      "31568 1 312 0.023 variable\n",
      "40151 41 389 0.029 variable\n",
      "40515 42 835 0.062 variable\n",
      "41440 43 1018 0.076 variable\n",
      "42299 44 334 0.025 variable\n",
      "49159 45 133 0.01 variable\n",
      "55635 110 270 0.02 variable\n",
      "56131 111 342 0.026 variable\n",
      "60257 112 6 0.0 variable\n",
      "66455 79 313 0.023 variable\n",
      "67545 80 459 0.034 variable\n",
      "69207 81 263 0.02 variable\n",
      "73169 48 525 0.039 variable\n",
      "73346 49 1034 0.077 variable\n",
      "74667 50 661 0.049 variable\n",
      "82540 47 414 0.031 variable\n",
      "105960 187 541 0.04 variable\n",
      "207066 10 22 0.002 variable\n",
      "207152 11 29 0.002 variable\n",
      "207272 12 20 0.001 variable\n",
      "207368 13 14 0.001 variable\n",
      "207439 14 13 0.001 variable\n",
      "239671 228 2 0.0 variable\n",
      "239684 229 23 0.002 variable\n",
      "239756 230 17 0.001 variable\n",
      "239825 231 17 0.001 variable\n",
      "239916 232 8 0.001 variable\n",
      "239957 233 9 0.001 variable\n",
      "251304 234 20 0.001 variable\n",
      "251399 235 9 0.001 variable\n",
      "276429 83 20 0.001 variable\n",
      "276540 84 41 0.003 variable\n",
      "276710 85 37 0.003 variable\n",
      "276849 86 43 0.003 variable\n",
      "277048 87 33 0.002 variable\n",
      "277198 88 38 0.003 variable\n",
      "277363 89 12 0.001 variable\n",
      "323056 124 5 0.0 variable\n",
      "323072 151 2 0.0 variable\n",
      "323083 152 30 0.002 variable\n",
      "323224 153 31 0.002 variable\n",
      "323371 154 29 0.002 variable\n",
      "323490 155 21 0.002 variable\n",
      "323602 156 36 0.003 variable\n",
      "323767 157 37 0.003 variable\n",
      "323941 158 9 0.001 variable\n",
      "Arbre global sauvegardé dans modbus_global_tree.pkl\n",
      "Arbre global exporté au format DOT dans modbus_global_tree.dot\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import deque\n",
    "\n",
    "FLOWS_PICKLE = \"modbus_flows.pkl\"\n",
    "TREES_TAGGED_PICKLE = \"modbus_trees_tagged.pkl\"\n",
    "\n",
    "OUTPUT_GLOBAL_DOT = \"modbus_global_tree.dot\"\n",
    "\n",
    "THRESHOLD = 0.95\n",
    "\n",
    "\n",
    "def load_flows():\n",
    "    return pd.read_pickle(FLOWS_PICKLE)  # dict: flow_key -> list[list[int]]\n",
    "\n",
    "\n",
    "def build_global_tree(flows):\n",
    "    G = nx.DiGraph()\n",
    "    root = 0\n",
    "    G.add_node(root, byte=None, count=0)\n",
    "\n",
    "    next_node_id = 1\n",
    "\n",
    "    for flow_key, messages in flows.items():\n",
    "        print(f\"Ajout des messages du flux {flow_key} (messages: {len(messages)})\")\n",
    "        for msg in messages:\n",
    "            current = root\n",
    "            G.nodes[current][\"count\"] += 1\n",
    "\n",
    "            for b in msg:\n",
    "                child = None\n",
    "                for succ in G.successors(current):\n",
    "                    if G.nodes[succ].get(\"byte\") == b:\n",
    "                        child = succ\n",
    "                        break\n",
    "\n",
    "                if child is None:\n",
    "                    child = next_node_id\n",
    "                    next_node_id += 1\n",
    "                    G.add_node(child, byte=b, count=0)\n",
    "                    G.add_edge(current, child)\n",
    "\n",
    "                current = child\n",
    "                G.nodes[current][\"count\"] += 1\n",
    "\n",
    "    return G, root\n",
    "\n",
    "\n",
    "def mark_node_types(G, root, threshold=THRESHOLD):\n",
    "    G.nodes[root][\"type\"] = \"root\"\n",
    "    G.nodes[root][\"ratio\"] = 1.0\n",
    "\n",
    "    for parent, child in G.edges():\n",
    "        parent_count = G.nodes[parent].get(\"count\", 0)\n",
    "        child_count = G.nodes[child].get(\"count\", 0)\n",
    "\n",
    "        ratio = child_count / parent_count if parent_count > 0 else 0.0\n",
    "        G.nodes[child][\"ratio\"] = ratio\n",
    "\n",
    "        if ratio >= threshold:\n",
    "            G.nodes[child][\"type\"] = \"constant\"\n",
    "        else:\n",
    "            G.nodes[child][\"type\"] = \"variable\"\n",
    "\n",
    "\n",
    "def export_global_tree_dot(G, root, dot_path):\n",
    "    dot = nx.DiGraph()\n",
    "\n",
    "    for node in G.nodes():\n",
    "        data = G.nodes[node]\n",
    "\n",
    "        if node == root:\n",
    "            label = \"ROOT\"\n",
    "            color = \"black\"\n",
    "            shape = \"doublecircle\"\n",
    "        else:\n",
    "            byte = data.get(\"byte\")\n",
    "            count = data.get(\"count\", 0)\n",
    "            ratio = data.get(\"ratio\", 0.0)\n",
    "            ntype = data.get(\"type\", \"unknown\")\n",
    "\n",
    "            label = f\"byte={byte}\\\\ncount={count}\\\\nratio={ratio:.2f}\\\\n{ntype}\"\n",
    "\n",
    "            color = \"green\" if ntype == \"constant\" else \"red\"\n",
    "            shape = \"circle\"\n",
    "\n",
    "        dot.add_node(\n",
    "            node,\n",
    "            label=label,\n",
    "            color=color,\n",
    "            shape=shape\n",
    "        )\n",
    "\n",
    "    for u, v in G.edges():\n",
    "        dot.add_edge(u, v)\n",
    "\n",
    "    nx.drawing.nx_pydot.write_dot(dot, dot_path)\n",
    "    print(f\"Arbre global exporté au format DOT dans {dot_path}\")\n",
    "\n",
    "\n",
    "\n",
    "flows = load_flows()\n",
    "\n",
    "print(\"Construction de l'arbre global...\")\n",
    "G_global, root_global = build_global_tree(flows)\n",
    "print(\"Nombre de noeuds :\", G_global.number_of_nodes())\n",
    "print(\"Nombre d'arêtes :\", G_global.number_of_edges())\n",
    "\n",
    "print(\"Marquage constant / variable...\")\n",
    "mark_node_types(G_global, root_global, THRESHOLD)\n",
    "\n",
    "depths = compute_depths(G_global, root_global)\n",
    "print(\"Niveau 1 (après la racine) :\")\n",
    "for n in G_global.nodes():\n",
    "    if depths.get(n) == 1:\n",
    "        print(\n",
    "            n,\n",
    "            G_global.nodes[n].get(\"byte\"),\n",
    "            G_global.nodes[n].get(\"count\"),\n",
    "            round(G_global.nodes[n].get(\"ratio\", 0.0), 3),\n",
    "            G_global.nodes[n].get(\"type\")\n",
    "            )\n",
    "\n",
    "pd.to_pickle((G_global, root_global), OUTPUT_GLOBAL_PICKLE)\n",
    "print(\"Arbre global sauvegardé dans\", OUTPUT_GLOBAL_PICKLE)\n",
    "    \n",
    "export_global_tree_dot(G_global, root_global, OUTPUT_GLOBAL_DOT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6a6b5c",
   "metadata": {},
   "source": [
    "### 4- Scénarios et cas d'utilisation (reproductibles)\n",
    "Dans l'article, les auteurs présentent deux scénarios bien précis :\n",
    "\n",
    "Le premier scénario de validation repose sur l'étude du protocole industriel Modbus, mis en œuvre au sein d'un banc d'essai dédié aux systèmes de contrôle industriel (SCI). Pour générer un jeu de données pertinent, une série d'opérations de lecture et d'écriture a été effectuée manuellement de manière répétée, en utilisant une vaste gamme de paramètres conformes aux spécifications légales du protocole. Cette méthodologie a permis la collecte d'un échantillon massif d'environ 20 000 paires de requêtes-réponses. Afin de garantir la reproductibilité de l'expérience et la cohérence de l'analyse, l'outil editcap de la suite Wireshark a été utilisé pour uniformiser les ports sources et destinations, permettant ainsi à l'algorithme de traiter l'ensemble des paquets comme un flux unique et structuré.\n",
    "\n",
    "Le second scénario se concentre sur le protocole MQTT, pilier de l'Internet des objets (IoT), testé dans un environnement contrôlé utilisant le serveur open source Eclipse Mosquitto et le client HiveMQ WebSocket. L'objectif de cette manipulation était de couvrir le spectre fonctionnel le plus large possible en exécutant un maximum d'opérations avec diverses combinaisons de paramètres. Le trafic ainsi généré a été capturé directement sur le serveur via Wireshark, aboutissant à un échantillon de 1 200 paquets. Ce cas d'utilisation démontre la capacité de la méthode GrAMeFFSI à s'adapter à des protocoles modernes, plus légers mais structurellement différents des protocoles industriels classiques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d8d5a",
   "metadata": {},
   "source": [
    "### 5- Avantages de l’approche proposée\n",
    "Les résultats expérimentaux présentés dans la publication montrent que l’approche GrAMeFFSI atteint une correction et une couverture parfaites, égales à 1.0, sur l’ensemble des protocoles testés par les auteurs. Cela signifie que tous les champs pertinents ont été correctement identifiés sans générer de faux positifs dans les scénarios évalués. Ces performances élevées démontrent l’efficacité de l’approche lorsque les conditions expérimentales sont favorables et que les données sont suffisamment représentatives.\n",
    "\n",
    "Un autre avantage majeur de GrAMeFFSI réside dans l’utilisation d’une modélisation par graphes pour représenter la structure des messages. Cette représentation permet de distinguer naturellement des types de messages mutuellement exclusifs, c’est-à-dire des messages partageant un même protocole mais correspondant à des fonctions ou commandes différentes. Grâce à l’analyse des chemins et des sous-graphes, l’algorithme parvient à isoler ces structures sans connaissance préalable du protocole.\n",
    "\n",
    "Enfin, les auteurs montrent que, lorsque les traces réseau sont de haute qualité (grand nombre de messages, faible bruit, structure stable), l’exactitude ajustée dépasse 95 %. Ce résultat confirme que la méthode est particulièrement bien adaptée à des environnements industriels ou embarqués où les communications sont régulières et répétitives, comme les protocoles SCADA, IoT ou automobiles.\n",
    "\n",
    "#### <u>Limites identifiées de la méthode</u>\n",
    "\n",
    "Une première limite importante concerne le chiffrement des communications. L’approche GrAMeFFSI repose sur l’analyse statistique et structurelle des octets observés dans les messages. Lorsque le trafic est chiffré ou obfusqué, cette structure disparaît, rendant impossible toute inférence du format ou de la sémantique des champs. Cette limitation est inhérente à toutes les méthodes d’analyse passive de protocoles binaires.\n",
    "\n",
    "La qualité et la quantité des données d’entrée constituent également un facteur critique. Les auteurs soulignent que, lorsque le nombre de messages observés est insuffisant ou que les traces sont bruitées, l’algorithme peut produire des erreurs d’inférence. Par exemple, des champs de longueur ou de type peuvent être incorrectement détectés comme constants si leur variabilité n’apparaît pas dans les données disponibles. Cette dépendance aux données souligne la nécessité de disposer de traces longues et représentatives pour garantir des résultats fiables.\n",
    "\n",
    "Enfin, GrAMeFFSI ne prend pas en charge les champs dits split-byte, c’est-à-dire les champs encodés sur quelques bits seulement à l’intérieur d’un octet. Ce type d’encodage est courant dans certains protocoles comme MQTT, où plusieurs drapeaux binaires sont regroupés dans un même octet. L’algorithme, basé sur une analyse octet par octet, ne peut pas actuellement détecter ni interpréter correctement ce genre de structure fine.\n",
    "\n",
    "<u>Commentaires sur la publication</u>\n",
    "\n",
    "<u>Points positifs</u> : L’un des principaux atouts de la publication réside dans le choix de protocoles ouverts et largement documentés, tels que (Modbus, MQTT) combine a des outils accessibles (Wireshark), garantissent une excellente reproductibilité. La formalisation mathématique rigoureuse des métriques (ratios, fréquences) rend l'algorithme transparent et facilite son implémentation.\n",
    "\n",
    "<u>Hypothèses omises et limites</u> :\n",
    "La publication repose implicitement sur plusieurs hypothèses fortes qui ne sont pas explicitement discutées.Nous avons entre autre: \n",
    "\n",
    "* Qualité des données : L'article suppose des captures parfaites. En réalité, les pertes ou duplications de paquets pourraient fausser les statistiques de classification.\n",
    "\n",
    "* Arbitraire des seuils : Le seuil d'énumération (8-20) est empirique. L'absence de méthode systématique pour l'ajuster limite la robustesse de l'approche face à des protocoles totalement inconnus ou des jeux de données restreints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134fc913",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Ce projet nous a permis de mettre en œuvre l'approche GrAMeFFSI, une méthode d'inférence automatique de protocoles binaires basée sur l'analyse de graphes orientés. L'objectif principal était de reconstruire la structure et la sémantique de protocoles inconnus à partir de traces réseau, sans connaissance préalable, en distinguant les champs constants des variables via l'analyse de fréquences.\n",
    "La démarche a consisté à traduire les concepts théoriques de l'article en une implémentation Python appliquée au protocole Modbus/TCP. L'algorithme que nous avons développé assure l'extraction des données depuis des fichiers .pcap, le regroupement par flux, la construction d'un arbre de format global et la classification automatisée des nœuds.\n",
    "Les résultats valident l'efficacité de l'analyse par graphes sur des flux non chiffrés, permettant une identification précise des invariants structurels. Toutefois, l'étude confirme également les limites intrinsèques à cette méthode, notamment sa sensibilité à la qualité du jeu de données et son inopérabilité face au chiffrement. Ce travail offre ainsi une base solide pour explorer des problématiques plus complexes, comme la détection de champs codés sur quelques bits ou l'analyse d'autres protocoles industriels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
